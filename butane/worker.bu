# Worker Node Butane configuration for Fedora CoreOS
# Complete configuration for worker nodes
# Butane transpiles to Ignition JSON format
# Reference: https://coreos.github.io/butane/

variant: fcos
version: 1.5.0

# Storage configuration
storage:
  disks:
    # Configure nvme1n1 for Longhorn - wipe partitions but don't format
    - device: /dev/nvme1n1
      wipe_table: true
      partitions:
        - number: 1
          size_mib: 0  # Use entire disk
          label: longhorn-nvme1n1
          type_guid: 0FC63DAF-8483-4772-8E79-3D69D8477DE4  # Linux filesystem data

  files:
    # Enable automatic updates and reboots anytime
    - path: /etc/zincati/config.d/55-updates-strategy.toml
      mode: 0644
      contents:
        inline: |
          [updates]
          enabled = true

    # Spread out reboots across the fleet to avoid all nodes rebooting at once
    - path: /etc/zincati/config.d/51-rollout-wariness.toml
      mode: 0644
      contents:
        inline: |
          [identity]
          # 0.0 = eager updates, 1.0 = very cautious
          # 0.5 = moderate delay to spread reboots across fleet
          rollout_wariness = 0.5

    # Disable swap
    - path: /etc/systemd/zram-generator.conf
      mode: 0644
      contents:
        inline: |
          # Disable zram swap for Kubernetes
          [zram0]

    # Kernel modules for Kubernetes
    - path: /etc/modules-load.d/kubernetes.conf
      mode: 0644
      contents:
        inline: |
          overlay
          br_netfilter

    # Sysctl settings for Kubernetes
    - path: /etc/sysctl.d/kubernetes.conf
      mode: 0644
      contents:
        inline: |
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
          net.ipv4.conf.all.forwarding        = 1
          net.ipv6.conf.all.forwarding        = 1
          fs.inotify.max_user_watches         = 524288
          fs.inotify.max_user_instances       = 512

    # Configure chronyd for time synchronization
    - path: /etc/chrony.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          pool pool.ntp.org iburst
          driftfile /var/lib/chrony/drift
          makestep 1.0 3
          rtcsync
          logdir /var/log/chrony

    # Create directory for kubectl configs
    - path: /etc/kubernetes
      mode: 0755
      user:
        name: root
      group:
        name: root

    # kubeadm join configuration for worker nodes
    - path: /etc/kubernetes/kubeadm-join-config.yaml
      mode: 0644
      contents:
        inline: |
          # This will be populated during cluster join
          # Placeholder for kubeadm join config

    # Node labels configuration
    - path: /etc/kubernetes/node-labels.conf
      mode: 0644
      contents:
        inline: |
          # Node labels will be applied after joining cluster
          # Populated from inventory/servers.yml

    # Configure kubelet extra args for worker
    - path: /etc/default/kubelet
      mode: 0644
      contents:
        inline: |
          KUBELET_EXTRA_ARGS="--node-labels=node-role.kubernetes.io/worker="

    # Create fstab (but don't mount the Longhorn devices here)
    - path: /etc/fstab
      mode: 0644
      contents:
        inline: |
          # /etc/fstab: static file system information.
          #
          # <file system> <mount point>   <type>  <options>       <dump>  <pass>
          # Longhorn devices will be managed by Longhorn CSI
          # /dev/disk/by-label/longhorn-nvme1n1
          # is reserved for Longhorn and should not be mounted manually

    # Create Longhorn configuration file
    - path: /etc/longhorn/longhorn-defaults.yaml
      mode: 0644
      contents:
        inline: |
          # Default Longhorn settings optimized for no local mirroring
          # Replication is handled across nodes, not within a single node
          storage:
            # Use all available labeled devices
            nodeLevelSoftAntiAffinity: true
            # Allow scheduling on nodes with no disks (for control plane nodes)
            defaultDataLocality: disabled
            # Disable automatic node eviction
            nodeDownPodDeletionPolicy: do-nothing

  directories:
    # Create necessary directories
    - path: /var/lib/kubelet
      mode: 0755
    - path: /var/lib/etcd
      mode: 0700
    - path: /etc/kubernetes/manifests
      mode: 0755
    - path: /opt/cni/bin
      mode: 0755
    - path: /var/lib/containerd
      mode: 0755
    - path: /var/lib/kubelet/pods
      mode: 0755
    # Create Longhorn config directory
    - path: /etc/longhorn
      mode: 0755

# System configuration
systemd:
  units:
    # Enable and start essential services
    - name: chronyd.service
      enabled: true

    # Load kernel modules at boot
    - name: systemd-modules-load.service
      enabled: true

    # Apply sysctl settings at boot
    - name: systemd-sysctl.service
      enabled: true

    # Docker is not needed, we'll use containerd
    - name: docker.service
      mask: true

    # Custom service to disable swap
    - name: disable-swap.service
      enabled: true
      contents: |
        [Unit]
        Description=Disable swap for Kubernetes
        After=local-fs.target

        [Service]
        Type=oneshot
        ExecStart=/usr/sbin/swapoff -a
        RemainAfterExit=true

        [Install]
        WantedBy=multi-user.target

    # Enable kubelet service (will be installed later)
    - name: kubelet.service
      enabled: true

    # Enable containerd service
    - name: containerd.service
      enabled: true

    # Custom service to prepare worker node
    - name: prepare-worker.service
      enabled: true
      contents: |
        [Unit]
        Description=Prepare node for Kubernetes worker
        After=network-online.target
        Wants=network-online.target
        Before=kubelet.service
        ConditionPathExists=!/var/lib/kubelet/config.yaml

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/bin/sh -c 'echo "Worker node ready for Kubernetes installation. Longhorn device available: /dev/disk/by-label/longhorn-nvme1n1"'

        [Install]
        WantedBy=multi-user.target

# Passwd configuration
passwd:
  users:
    # Core user (default Fedora CoreOS user)
    - name: core
      ssh_authorized_keys:
        - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIM/H7Jp2RgC1xtg1nyzpmhzOTmUz3n+PQPsk83BzUskg github-actions@yral.com
        - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEk4PvXhngz7NQRu/OYThH+gH/BLRzncjiAMNo16NCHV saikatdas0790@gmail.com
      groups:
        - wheel
        - sudo
        - docker
      # Allow passwordless sudo
      shell: /bin/bash

# Kernel arguments
kernel_arguments:
  # Enable cgroups v2 for modern Kubernetes
  should_exist:
    - systemd.unified_cgroup_hierarchy=1
